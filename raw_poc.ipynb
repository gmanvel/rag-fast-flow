{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60458ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in ./.venv/lib/python3.13/site-packages (1.26.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH=\"/Users/gmanvel/repos/rag-fast-flow/data/fast_flow.pdf\"\n",
    "JSON_OUTPUT_PATH=\"/Users/gmanvel/repos/rag-fast-flow/data/fast_flow_extracted.json\"\n",
    "%pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f33061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import re\n",
    "\n",
    "HEADER_SIZE = 34\n",
    "SECTION_SIZE = 18\n",
    "CONTENT_SIZE = 13\n",
    "TOL = 0\n",
    "\n",
    "def dominant_size(block):\n",
    "    sizes = []\n",
    "    for line in block.get(\"lines\", []):\n",
    "        for span in line.get(\"spans\", []):\n",
    "            sizes.append(span.get(\"size\"))\n",
    "    if not sizes:\n",
    "        return None\n",
    "    rounded = [round(s, 1) for s in sizes if s is not None]\n",
    "    if not rounded:\n",
    "        return None\n",
    "    freq = {}\n",
    "    for s in rounded:\n",
    "        freq[s] = freq.get(s, 0) + 1\n",
    "    return max(freq.items(), key=lambda kv: kv[1])[0]\n",
    "\n",
    "def block_text(block):\n",
    "    parts = []\n",
    "    for line in block.get(\"lines\", []):\n",
    "        for span in line.get(\"spans\", []):\n",
    "            parts.append(span.get(\"text\", \"\"))\n",
    "    text = \"\".join(parts)\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    text = re.sub(r\"\\s*\\n\\s*\", \"\\n\", text)\n",
    "    return text.strip()\n",
    "\n",
    "def classify(size):\n",
    "    if size is None:\n",
    "        return None\n",
    "    if abs(size - HEADER_SIZE) <= TOL:\n",
    "        return \"header\"\n",
    "    if abs(size - SECTION_SIZE) <= TOL:\n",
    "        return \"section\"\n",
    "    if abs(size - CONTENT_SIZE) <= TOL:\n",
    "        return \"content\"\n",
    "    return None\n",
    "\n",
    "def sanitize_str(s):\n",
    "    if s is None:\n",
    "        return s\n",
    "    return s.encode(\"utf-8\", \"replace\").decode(\"utf-8\")\n",
    "\n",
    "def sanitize(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {sanitize(k): sanitize(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, list):\n",
    "        return [sanitize(x) for x in obj]\n",
    "    if isinstance(obj, str):\n",
    "        return sanitize_str(obj)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e38d9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(FILE_PATH)\n",
    "\n",
    "point = []\n",
    "current_header = None\n",
    "current_section = None\n",
    "\n",
    "for page in doc[2:64]:\n",
    "    data = page.get_text(\"dict\")\n",
    "    blocks = data.get(\"blocks\", [])\n",
    "    blocks_sorted = sorted(blocks, key=lambda b: (b.get(\"bbox\", [0,0,0,0])[1], b.get(\"bbox\", [0,0,0,0])[0]))\n",
    "    for b in blocks_sorted:\n",
    "        if b.get(\"type\") != 0:\n",
    "            continue\n",
    "        size = dominant_size(b)\n",
    "        kind = classify(size)\n",
    "        if kind is None:\n",
    "            continue\n",
    "        text = block_text(b)\n",
    "        if not text:\n",
    "            continue\n",
    "        if kind == \"header\":\n",
    "            current_header = {\"header\": text, \"sections\": []}\n",
    "            point.append(current_header)\n",
    "            current_section = None\n",
    "        elif kind == \"section\":\n",
    "            if current_header is None:\n",
    "                current_header = {\"header\": \"\", \"sections\": []}\n",
    "                point.append(current_header)\n",
    "            current_section = {\"tile\": text, \"content\": \"\"}\n",
    "            current_header[\"sections\"].append(current_section)\n",
    "        elif kind == \"content\":\n",
    "            if current_section is None:\n",
    "                if current_header is None:\n",
    "                    current_header = {\"header\": \"\", \"sections\": []}\n",
    "                    point.append(current_header)\n",
    "                current_section = {\"tile\": \"\", \"content\": \"\"}\n",
    "                current_header[\"sections\"].append(current_section)\n",
    "            if current_section[\"content\"]:\n",
    "                current_section[\"content\"] += text #\"\\n\" + text\n",
    "            else:\n",
    "                current_section[\"content\"] = text\n",
    "\n",
    "for h in point:\n",
    "    h[\"header\"] = h[\"header\"].strip()\n",
    "    cleaned_sections = []\n",
    "    for s in h[\"sections\"]:\n",
    "        s[\"tile\"] = s.get(\"tile\", \"\").strip()\n",
    "        s[\"content\"] = s.get(\"content\", \"\").strip()\n",
    "        if s[\"tile\"] or s[\"content\"]:\n",
    "            cleaned_sections.append(s)\n",
    "    h[\"sections\"] = cleaned_sections\n",
    "\n",
    "point = sanitize(point)\n",
    "\n",
    "#result\n",
    "\n",
    "# import json\n",
    "# with open(JSON_OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(result, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45283474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in ./.venv/lib/python3.13/site-packages (0.12.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.13/site-packages (from tiktoken) (2025.9.18)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.venv/lib/python3.13/site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2025.10.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29219f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'header': 'Introduction',\n",
       "  'sections': [{'tile': '',\n",
       "    'content': 'Matthew Skelton, Co-author of Team TopologiesIn the world of modern software development, speed is a major differentiator. The arrival of cloud computing has transformed the way in which software is developed and has substantially reduced delivery times. Any organization that cannot deliver (and sense the market) fast enough will struggle to compete, and therefore achieving a fast flow of change is essential. Business agility and faster software delivery requires organizations to not only consider the technical aspects of software development but also the social structures and team interactions. Effective flow of value requires an understanding of boundaries between domains, something that Domain Driven Design (DDD) has been helping to achieve for many years. However, it is also important to understand the dependencies and interactions between the teams that own those domains. This is something that can be achieved by looking at the organization through a Team Topologies (TT) lens.In 2003, Eric Evans produced the first edition of Domain-Driven Design: Tackling Complexity in the Heart of Software with the aim of simplifying how software is developed by allowing developers, domain experts, business owners and clients to communicate effectively with each other in order to solve complex problems. For nearly 20 years this book has been the cornerstone of the DDD community and has long stood the test of time. During that time approaches to software development have evolved, the introduction of cloud computing etc has enabled a paradigm shift towards thinking about software boundaries differently and optimizing for the flow of value through an organization.The book Team Topologies by Matthew Skelton and Manuel Pais — published in September 2019 — introduced a new way of thinking about organization dynamics and software architecture design, via the principles of well-defined team types and team interactions, by taking a team-first approach, and considering cognitive load as a constraining factor on team size and team3interactions. TT provides a fresh combination of principles and practices that help evolve organizations towards effective collaboration, autonomy, delivery focus and product alignment ultimately enabling a faster flow of change.Several people in the wider DDD community, especially those engaged in the concept of socio-technical architectures, have identified some similar concepts and intentions between DDD and TT but with subtle differences in approach that encourage them to be complementary. This mini-book explores the similarities, differences and crossovers between DDD and TT in a series of insightful articles that will help you to apply the ideas from both areas effectively.4',\n",
       "    'token_count': 484}]},\n",
       " {'header': 'Building Adaptive Systems for a Fast Flow of Change',\n",
       "  'sections': [{'tile': '',\n",
       "    'content': 'Susanne Kaiser, independent tech consultantIn a world of rapid changes and increasing uncertainty, organizations must adapt and evolve continuously to remain competitive and excel in the market. To adapt and evolve, an organization, its business strategy, and its architecture must be able to anticipate and absorb change.Combining Wardley Mapping, Domain-Driven Design, and Team Topologies helps us to connect the dots between business strategy, software design and architecture, and team organization to build adaptive systems for a fast flow of change.',\n",
       "    'token_count': 100},\n",
       "   {'tile': 'The business strategy perspective with Wardley Mapping',\n",
       "    'content': 'Wardley Mapping is a strategy framework invented by Simon Wardley. Wardley Mapping helps to design and evolve effective business strategies based on situational awareness and movement following a strategy cycle. According to Wardley, the strategy cycle ‘is a representation of change and how we need to react to it’. The strategy cycle consists of five sections based on Sun Tzu’s five factors that matter when competing (or going to war):5The strategy cycle starts with the purpose — the ‘why’ of the business. The purpose represents the reason why customers choose your business over others and what inspires the customer to act. The landscape is a description of the competitive environment in which an organization is operating. The landscape is visualized by the Wardley Map. The climate consists of patterns that describe external forces and rules impacting the landscape, over which we have no control. Discovering and understanding the climatic patterns is important to see how the landscape is changing. Some of the climatic patterns can be anticipated, providing a competitive advantage. The doctrine describes universal, context-independent principles that all organizations can apply regardless of their landscape. These are principles for successful operation that enable organizations to absorb and adapt gracefully to a fast flow of change (organizational fitness). The leadership is the context-specific decision-making component of the organization: what strategy to choose, considering the landscape, climate, and doctrine.In this article, we are focusing on the landscape and some doctrinal principles.6',\n",
       "    'token_count': 290},\n",
       "   {'tile': 'Visualizing the landscape - the Wardley Map',\n",
       "    'content': 'The landscape is a description of the environment in which an organization is operating and competing. The landscape is represented on a map called the Wardley Map. The Wardley Map is composed of a y-axis depicting a value chain and an x-axis representing evolution stages. A value chain describes what is needed to add and deliver value to a user. Creating a Wardley Map starts with defining the value chain. From top to bottom, a value chain consists of users, user needs, and components fulfilling the user needs directly or facilitating other components in the value chain. Components at the top are most visible with the biggest value to the users, e.g. where users are interacting directly with the system. The components at the bottom are less visible to the users. Users and user needs form the anchor of the map; all subsequent components are positioned in relation to these elements.Let’s build an example value chain for a conference event planning solution that enables conference organizers to manage an event (see figure 2).This solution mainly addresses the conference organizers and speakers as users. To identify the users’ needs we can articulate a user journey. The conference organizers start their user journey with managing a call for papers (CfP) to which7the speakers can submit their session proposals. The organizers need to evaluate the submitted session proposals, build and publish a schedule from the accepted sessions, and communicate with the speakers. Both conference organizers and speakers need to sign-up and sign-in as well.In the next step, we go further down the value chain and identify the components that fulfil the users’ needs. We start with a single conference event planner component that contains the business functions that fulfill the aforementioned user needs directly. Later, we are splitting each component into smaller parts when bringing in the Domain-Driven Design perspective. The conference event planner component needs to store some sort of state. For that purpose, we need a data storage component that facilitates the conference event planner component. It is less visible to the user, so is positioned further down on the y-axis. For search functionality and event-driven, decoupled communication, we need to integrate a search engine and a message broker. They both facilitate the conference event planner component. The conference event planner component, data storage, search engine, and message broker need an environment in which their software is executed: the compute platform. This compute platform is running on top of a virtual machine.Once we have defined the value chain, the next step is to map each component of the value chain to evolution stages on the x-axis. The evolution stages start with Genesis on the left, a stage that involves addressing the characteristics of new, undefined, and constantly changing components. Then comes ‘Custom-Built’, then ‘Product’ (+rental), such as off-the-shelf products or open-source software, then ‘Commodity’ (+utility).As the components of a value chain evolve, their characteristics change. Asking about the characteristics of each component helps us to identify which component belongs to which evolution stage. For example, how well-understood and well-defined is the component? Is the component available as a product or utility service or is it rather new? How widespread is this component? Are all competitors using this component? Is this component providing a competitive advantage? Our conference event planner component, providing a competitive advantage, shall go into ‘custom-built’. We are planning to use open-source solutions for the search engine, data storage, and message broker components, which locates them in the ‘product’ (+rental) evolution stage. The components are going to be packaged in containers as a compute platform running on top8of a cloud-hosted virtual machine residing in the ‘commodity’ (+utility) evolution stage.Before switching to the climatic patterns as the next section of the strategy cycle, we would like to focus on the conference event planner component by bringing in the Domain-Driven Design perspective. This helps to analyze and understand the problem domain and partition the problem domain into modular parts.',\n",
       "    'token_count': 799},\n",
       "   {'tile': 'The Domain-Driven Design perspective',\n",
       "    'content': 'Domain-Driven Design (DDD) is about designing software based on Domain Models, as proposed by Eric Evans in his book, Domain-Driven Design: Tackling Complexity in the Heart of Software. The core concept of DDD is that to build better software, its design needs to align with the business domain, business needs, and business strategy. Before diving straight into developing a technical solution that solves the user needs, it is necessary to understand the problem domain, and that’s where DDD is very helpful. An essential part of DDD is the collaboration between domain experts and development teams. They analyze the problem domain to obtain domain knowledge. The problem domain or business domain refers to the scope, area, or process of an organization. The domain9knowledge should be free of technical jargon and described in terms of a shared, business-domain oriented language - the ubiquitous language.DDD comes with patterns and practices consisting of strategic and tactical design. To illustrate these, I would like to reuse the y-axis of a Wardley Map and apply a top-down approach. We start with the problem space of strategic design at the top and go to the solution space of tactical design at the bottom. Analyzing the business domain and discovering subdomains as subparts of the problem domain help to build the problem space of strategic design. In connection with Wardley Mapping, the problem domain can be considered as the users and their user needs.When we switch to the strategic design’s solution space, we start by decomposing the problem domain (including subdomains) into modular components (the Bounded Contexts) and mapping interaction patterns between them (the context maps). Later, when we architect and implement a solution fitting the problem domain, we are moving to the tactical design’s solution space.In this article, we are focusing on strategic design with its subdomains and Bounded Contexts and leaving out context maps and tactical design (for simplicity).10',\n",
       "    'token_count': 385},\n",
       "   {'tile': 'Discovering subdomains and determining their evolution stages',\n",
       "    'content': 'Distilling the business domain reduces complexity by partitioning the broad, abstract business domain into smaller, concrete parts: the subdomains. However, not all subdomains are equal. Some are more valuable to the business than others and this is reflected by assigning them a category: core, supporting, or generic (see Figure 5). These different categories can help us find the subdomains and prioritize the development effort.The subdomain categories can be mapped to evolution stages. One of Wardley’s mapping principles is to use appropriate methods for each stage. There is no one-size-fits-all method, but appropriate methods per evolution stage, since each evolution stage comes with different characteristics that need to be handled differently. For Genesis and Custom-Built, it’s appropriate to build the components in-house, preferably using agile methods. For product (+rental), it’s more appropriate to use or buy off-the-shelf products or use open-source solutions, preferably using lean methods. For commodity (+utility), it’s appropriate to outsource to utility suppliers, preferably applying Six Sigma methods.11The core domain is the essential, business-critical part of the problem and it provides a competitive advantage. The core domain should be complex enough to make it difficult for competitors to copy or imitate. This subdomain tends to change often. The core domain is the subdomain to strategically invest in most and is supposed to be built in-house, residing predominantly in Genesis or Custom-Built stages. For example, the core domains for the conference event planner could revolve around managing the call for papers, handling submissions, evaluating sessions, and building the schedule.The supporting subdomain helps to support the core domain but does not on its own provide a competitive advantage. It tends to be quite simple and does not change often, but might - in some cases - require some form of specialization. If possible, buying or using off-the-shelf products or using open-source software is a good approach. For this reason, the supporting subdomain is mapped to the Product (+rental) evolution stage. If some level of specialization is required, custom-building the supporting subdomain might be necessary., In this case, the supporting subdomain moves into the Custom-Built evolution stage. In the context of the aforementioned conference event planner, the messaging subdomain is a candidate for a supporting subdomain. It does not provide a competitive advantage but supports the core domain in such a way that it eases the interaction between the conference organizers and the speakers during the conference event planning process.The generic subdomain is a subdomain that many business systems have. Examples include authentication and payment services. The generic subdomain is not core and does not provide a competitive advantage but is a category of products that businesses cannot work without. They can be complex but already solved by someone else. For the generic subdomain, it makes sense to buy or use off-the-shelf products or use open-source software or outsource to utility suppliers. This means that the generic subdomains are predominantly located in the Product (+rental) or Commodity (+utility) evolution stage. For the conference event planner, the identity and access management service that fulfills signing-in and signing-up of users is a good candidate for a generic subdomain.',\n",
       "    'token_count': 650},\n",
       "   {'tile': 'Domain Models and Bounded Contexts',\n",
       "    'content': 'At this point, we have identified the subdomain categories in the problem space of strategic design. When switching to the solution space of strategic12design, the next step is to decompose the solution, in this case the conference event planner, into modular components — the Bounded Contexts. A Bounded Context defines where a single Domain Model can be applied. A Domain Model represents the domain logic and business rules that are relevant to that area of the system. It forms a unit of mastery, purpose, and autonomy. But, a Domain Model cannot exist without a boundary, and that’s where the Bounded Context comes in. A Bounded Context provides different types of boundaries. A Bounded Context forms a linguistic and semantic boundary around the Domain Model so that the language of the Domain Model is consistent and clear inside its Bounded Context. A Bounded Context serves as an ownership boundary: it should be implemented by one team only, but a single team can own multiple Bounded Contexts. A Bounded Context also serves as a physical boundary and can be implemented as a separate solution. In addition, the architectural and business logic implementation patterns can vary from context to context.Conversations between domain experts and development teams about identifying the main outcomes of development may result in Bounded Contexts and Domain Models.At some point, we might encounter ambiguity. For example, a Domain Model called ‘session’ may have more than one meaning. A session scheduled for the agenda has different attributes and business rules from a session proposal submitted by a speaker. This requires adjusting the ubiquitous language (‘session’) by introducing the phrases ‘submitted session’ and ‘scheduled session’ to make the meanings consistent and clear. Adjusting the language is a good indicator of a Bounded Context.There are several techniques available to derive Bounded Contexts and Domain Models, such as EventStorming, Domain Storytelling, Example Mapping, User Story Mapping, etc.For our example, we derived the Bounded Contexts of submission handling, CfP management, session evaluation, schedule management, messaging, and identity and access management. We placed them in their evolution stages according to their related subdomain categories (see Figure 6).13',\n",
       "    'token_count': 438},\n",
       "   {'tile': 'Strategic design and Wardley’s Doctrine',\n",
       "    'content': 'The strategic design also helps to apply universal principles of Wardley’s Doctrine (see Figure 7). At DDD’s center is the close collaboration between domain experts and development teams, enabling us to analyze the business domain and challenge assumptions. Through this collaboration, we are gaining14domain knowledge, which helps us to know the details of the business domain. The domain knowledge is described in a shared language. Discovering the core domain that provides a competitive advantage lets us focus on high situational awareness and understand the landscape in which we are operating and competing. Decomposing our system into modular Bounded Contexts enables us to partition our problem domain into smaller contracts. Bounded Contexts form a unit of mastery, purpose, and autonomy that conforms with the related doctrinal principle. The subdomain categories can be mapped to evolution stages, which leads to using appropriate methods per evolution stage.After having visualized the landscape with a Wardley Map, discovered subdomain categories and their evolution stages, and decomposed the problem domain into Bounded Contexts, we next need to bring in the team organization perspective.',\n",
       "    'token_count': 218},\n",
       "   {'tile': 'The team organization perspective with Team Topologies',\n",
       "    'content': \"Conway’s Law states that ‘any organization that designs a system [...] will produce a design whose structure is a copy of the organization’s communication structure’. For example, an organization composed of functional silo teams, such as UI-, backend-, and database-administration teams will inevitably produce a multi-tier architecture consisting of presentation, business logic, and data storage tiers. There's nothing wrong with multi-tier architecture in general, but when implementing a change across several tiers requires handover between multiple teams, we increase communication and coordination efforts between teams, introducing bottlenecks, which impede delivery performance.To optimize for a fast flow of change, we need to avoid functional silo teams and handovers. Instead, we need to aim for autonomous, cross-functional teams that are designing, developing, testing, deploying, and operating the systems for which they are responsible. Small, long-lived teams need to own the systems or subsystems on which they work. Minimizing the team’s cognitive load is essential to avoid delivery bottlenecks. While communication within a team is desired, we have to restrict high-bandwidth communication between teams to enable fast flow.And that’s where Team Topologies comes in, as it ‘advocates for organization15design that optimizes for flow of change and feedback from running systems.’ Team Topologies introduces four well-defined team types (see Figure 8) and three well-defined interaction modes (see Figure 9), promoting organizational effectiveness.Stream-aligned Teams are aligned to a continuous stream of work, e.g. a product, a service, a set of features, etc. They have end-to-end responsibility and aim to produce a steady flow of feature deliveries and incorporate feedback. To focus on a fast flow of change, the stream-aligned teams rely on the other team types that aim to increase the autonomy of the stream-aligned teams and reduce their team cognitive load. Platform Teams are responsible for platforms that typically abstract away infrastructure, networking, and cross-cutting capabilities. They provide internal, self-service resources and tools for easily consuming that platform. Enabling Teams help other teams to acquire missing capabilities, e.g. making suggestions on tooling, practices, and frameworks. Complicated Subsystem Teams support other teams on particularly complicated subsystems that require specialized knowledge.Team Topologies also introduces three interaction modes (see Figure 9) for organizational effectiveness. With collaboration, teams work very closely together.16Collaboration is suitable for rapid discovery and innovation, e.g. when discovering new technologies. X-as-a-Service suits well when one team needs to use a code library, component, API, or platform that can be effectively provided by another team ‘as a service’. Facilitating comes into play when one team would benefit from the active help of another team. This interaction mode enhances the productivity, effectiveness, and flow of the help-receiving team.\",\n",
       "    'token_count': 571},\n",
       "   {'tile': 'Architecture for flow',\n",
       "    'content': 'Let’s put the three perspectives together and apply Team Topologies to our previously created Wardley Map including subdomain types and Bounded Contexts. Optimizing for a fast flow of change requires knowing where the most important changes in a system occur - the streams of changes. The first step in applying Team Topologies is identifying suitable streams of change. The previously identified user needs represent activity-oriented streams of change. Next is finding suitable team boundaries. The Bounded Contexts represent good team boundaries for stream-aligned teams as they serve as well-defined ownership boundaries forming a unit of purpose, mastery, and autonomy. Clear responsibility boundaries are necessary to optimize for team cognitive load. Assigning Bounded Contexts to a single team rather than sharing them across teams creates clear ownership. However, one team can own several Bounded Contexts. In addition, we need to match the boundary size to the team cognitive load and limit the number and complexity level of Bounded Contexts per team. The next step is to identify services needed to support a reliable flow of change. That brings the focus on the platform-related components of our Wardley Map, located in the Product (+rental) and Commodity (+utility) evolution stages. To focus on a fast flow of change, the stream-aligned teams rely on a platform team17providing an easily consumable platform-as-a-service. The platform team might start with a thinnest viable platform that is ‘just big enough’ and can evolve later into a digital platform with self-service APIs and tools. That might result in a team constellation illustrated in figure 10.',\n",
       "    'token_count': 320},\n",
       "   {'tile': 'Team Topologies and Wardley’s Doctrine',\n",
       "    'content': 'The combination of the four team types and the three interaction modes of Team Topologies promotes organizational effectiveness also from the perspective of Wardley’s doctrine (see Figure 11). Team Topologies helps to apply the doctrinal principles of ‘thinking small as in teams’, optimizing flow and reducing bottlenecks, providing purpose, mastery, and autonomy, and designing for constant evolution, where the system can handle a constant flow of changes without the need for constant restructuring.18',\n",
       "    'token_count': 92}]},\n",
       " {'header': 'About Team Topologies and Context Mapping',\n",
       "  'sections': [{'tile': '',\n",
       "    'content': 'Alberto Brandolini, EventStorming Creator and founder of AvanscopertaThe concept of Team Topologies, as depicted in the book by Matthew Skelton and Manuel Pais, is getting worldwide attention. Its focus on team structure and purpose is opening interesting discussions and many organizations are adopting the model as a reference for the organization of development teams.At the same time, Domain-Driven Design (DDD) practitioners have a sense of deja-vu since the problem space seems to overlap with some of the advanced concepts of Context Mapping found in DDD. This is my attempt to see the best of both worlds and the pros and cons of the different approaches.',\n",
       "    'token_count': 131},\n",
       "   {'tile': 'The problem space is mainly uncharted territory',\n",
       "    'content': 'Pais and Skelton hit a nerve with their book. Most organizations grow organically under the pressure of a never-empty backlog. As a result, teams growing in size will have to be split and competencies will progressively become more narrowed and specialized. However, the few criteria driving the splitting have been debated endlessly. Whichever the adopted decision - cut around business capabilities vs. cut around technical skills - the outcome is never perfect, leaving the decision-makers with a feeling of maybe the other approach could have been better...To make matters worse, every organization places the responsibility of sizing and structuring teams in different hands: is this the responsibility of a team leader or head of development? Or CTO, maybe? Do we need a specific role for that? Do we always need to escalate to the ecosystem level or is the collaboration between teams just a local issue?19',\n",
       "    'token_count': 174},\n",
       "   {'tile': 'Have you been Spotified?',\n",
       "    'content': 'This lack of reference models also explains the popularity of the Spotify Model. An organization that dared to experiment with a different model for team structure and collaboration quickly became a source of inspiration, with a lot of unintended consequences. As also happened with lean and Toyota, other organizations followed the model, without paying too much attention to the ingredients that made it viable in that specific context.In short, most nontrivial software development organizations experience some kind of friction in this space. Collaboration between software teams is one of the fundamental traits of successful companies, but frictionless collaboration seems to be a chimera, so it’s not a surprise if IT professionals are seeking guidance.',\n",
       "    'token_count': 130},\n",
       "   {'tile': 'Team Topologies categorizations',\n",
       "    'content': 'Team Topologies describes four team types:• Stream-aligned Team focused on a specific business capability, ideally cross-functional;• Platform Team providing common services to other teams;• Complicated Subsystem Team with high specialization and specific knowledge about one portion of the system;• Enabling Team experts who mentor and help other teams to evolve and improve.While these concepts are not new — they stem from observation of many different ecosystems — it is interesting to see that they provide a vocabulary and a reference model. You may want to consider this list of archetypes as attractors for what a good team should be, but you should also note that there are only four of them!Some weird things your organization is doing aren’t listed here, maybe for a good reason. These are reference implementations for teams that work well together.20',\n",
       "    'token_count': 162},\n",
       "   {'tile': 'Three interaction modes',\n",
       "    'content': 'In terms of relationships between teams, only three patterns are described:• Collaboration when two teams are working closely to a common goal for a limited period of time;• X-as-a-service when there is a contact in terms of usage, potentially on an ongoing basis, but little specific collaboration;• Facilitation, when a team is helping another to overcome impediments for a limited period of time.Once again, the list is short (so patterns that are not listed are interesting for their absence), and the patterns are attractors. Failing to define the type of engagement will leave space for ambiguities that will turn into frictions and delays.21',\n",
       "    'token_count': 129},\n",
       "   {'tile': 'Context Mapping patterns',\n",
       "    'content': 'Strategic Domain-Driven Design offers an interesting point of view on the same problem space, but with different constructs.There is little explicit reference to teams but the focus is mostly on Bounded Contexts (BCs) under the assumption that in a mid-sized software organization, there will be a close mapping between the two concepts.No, Bounded Contexts are defined as the limit of applicability of a given model. But the sophisticated domain understanding that is a fundamental ingredient of Domain-Driven Design, is only possible if a single team is responsible for a given portion of the model. They need to connect on the entire socio-technical stack (talking to business representatives, writing and testing the code, interacting with users, and so on).There’s some well-accepted wisdom in the DDD community about it, so, let’s make it explicit.Can a single team manage multiple BCs? Yes, this is the norm in small-sized organizations.But, well... most small organizations don’t seem to care much about boundary separation. In fact, the only way to achieve good separation is to explicitly enforce it: from big visible maps to segregation of the codebase.The hardest thing to manage is in fact the cognitive load of the developers, especially if the backlog priorities force them to switch from one Bounded Context to another.One can only be deeply focused on one model at a time. But without strong boundaries, it will be very easy to blur concepts that shouldn’t be mixed. Just like working in a chocolate shop without ever eating it. The odds are not in your favor.22Whilst one team/many models can happen, you’ve got to be very good at making the boundaries explicit.',\n",
       "    'token_count': 338},\n",
       "   {'tile': 'More teams, one BC',\n",
       "    'content': 'Can we have two teams working on the same model? Apparently, yes. I mean: drawing it seems straightforward.23Unfortunately, two teams in the same Bounded Context is usually a prelude to a riot. Teams typically have different backlogs and priorities and ambiguity will quickly rot in the codebase, accelerating the transition towards a Big Ball of Mud (BBoM). In general, BCs won’t be so big as to justify multiple teams working on them. So... No.Interestingly, the Spotify model seems to move a little in that direction, relaxing the ownership of the codebase. This reduces coordination costs (the communication bandwidth, again), while mitigating the risks of decreasing quality through strong engineering practices. However, they don’t have a BIG shared Bounded Context, but many smaller ones with relaxed ownership rules.',\n",
       "    'token_count': 167},\n",
       "   {'tile': 'One team per BC',\n",
       "    'content': 'The perfect choice seems to be one team per Bounded Context.One team, one Bounded Context. It seems the way to go, on paper.But… some details are left out of the picture. Like organization size, for example. I counted 20 different Bounded Contexts in our internal software the last time that I checked. Does it mean that we need 20*(7±2) developers to write our software? For a company of 6? Come on!Size isn’t the only problem here: the different BCs are not evolving at the same24pace. Some will be growing, others will stabilize and ideally be left untouched for a long time. But, the notion of an idle team isn’t popular in the enterprise; one risk being filling up a backlog just because the team is available. The association between a team and a Bounded Context is temporary and will change over time.',\n",
       "    'token_count': 182},\n",
       "   {'tile': 'Collaboration Patterns',\n",
       "    'content': 'The focus of Context Mapping isn’t on the shape of the teams but on the relationships between models that have to support collaboration. One interesting concept is that of being upstream or downstream: mapping the political influence that parties hold within one model versus the other. Based on this type of reasoning, we have a few patterns describing possible collaboration types. Here is a quick summary:• Partnership: two teams are mutually dependent and collaborate towards a common goal.• Customer-Supplier: the goal is still common, but the dependency is less symmetrical, and priorities may differ. Negotiations are however possible.• Conformist: no negotiations here. One model is adopted with minimal changes on the other side. The downstream party just gets what they are given.• Anti-Corruption Layer: still on the downstream side, but we are not adopting the external model. In fact, we’re writing a thick adapter to keep our model strictly separated from the outside one.• Open-Host: on the upstream side, our model can be made available to external users, on our conditions. Of course, we’ll need to make these conditions explicit with documentation and so on.• Published Language: a common language on the communication channel could make a larger conversation possible, especially if the conversation language is maintained by a third party.• Shared Kernel: a small portion of the software could be in common between different models, but this implies superior attention and quality in touching this code, not to mention the dependencies.• Separate Ways: the best dependency is the one we don’t have. Sometimes keeping things separated is the way.• Big Ball of Mud: when boundaries are not in place and the codebase becomes a scary place to work in.25In DDD, this categorization becomes interesting when drawing a Context Map which is a useful artifact in a brownfield scenario. Drawing the map forces me to ask the relevant questions before starting the project. For example, I’d wave a red flag if my team was expected to be conformist on an unreliable platform, on a critical project for the business.',\n",
       "    'token_count': 409},\n",
       "   {'tile': 'Satellite concepts',\n",
       "    'content': 'Since the early days, I enjoyed the ability of Context Mapping Patterns to capture the cost of the different approaches on different currencies. A Partnership requires less code but a lot of conversational bandwidth, while an Anti-Corruption Layer goes exactly in the opposite direction, writing more code since no conversation is possible. Conformist will let you go with little code and conversation, but asking a tribute in reduced quality instead. No such thing as a free lunch!Conversational bandwidth is the key currency here. Collaboration won’t happen if there’s not enough bandwidth to support it.',\n",
       "    'token_count': 115},\n",
       "   {'tile': 'Comparing the two approaches',\n",
       "    'content': 'The most obvious difference between Team Topologies and Context Mapping is that the latter doesn’t explicitly talk about teams, but about models instead. On the other hand, Team Topologies suggests optimizing for cognitive load, which26maps pretty well to the notion of having one team per Bounded Context.Talking about the different collaboration patterns, there’s some overlap between the TT and DDD approaches, like DDD Open-Host and TT Platform Team, or DDD Partnership and Customer-Supplier with TT Collaboration. But the most interesting difference seems to be another one.Team Topologies provides a reference towards a desirable to-be state, while DDD Context Mapping provides more fine-grained patterns for assessing the current state.A Big Ball of Mud is clearly not a desirable state, but it’s part of the dictionary needed to describe your horrible daily reality. I use Context Mapping to map the future state, but mainly as a software design tool, not so much as an organization design tool. Team Topologies seems to have an edge in being used as a reference model there.One thing that the two approaches have in common is the ability to make the consequences of team-model allocation decisions explicit. Collaborations are costly and these costs need to be properly accounted for. I’ve been in too many places where the management was inviting teams to communicate more while filling backlogs and adding deadlines, making communication virtually impossible.The Team Topologies lightweight dogmatism of ‘there are only 3 types of interaction’ (paraphrased) is a good way to force management to make choices and own consequences. Just telling people to collaborate and communicate is not a strategy.At the same time, quickly updating our current-state Context Map is still a great way to detect bullshit and inconsistencies in the current state of collaborations.27• “We are collaborating with team A. We have meetings every week!” \\uf0e8 Customer-Supplier?• “They just say ‘No’ to every single thing we ask.” \\uf0e8 No... Conformist.Team Topologies talks about fracture planes as a natural way to decompose the system into different streams. But I am too much into Domain-Driven Design to fall in love with this metaphor. Well, I know there are ideal places for cutting the system into loosely coupled Bounded Contexts and effectively splitting responsibilities between teams; I wrote an entire chapter in my book Introducing EventStorming about how to extract this information from a Big Picture EventStorming.But… I also know that when it comes to breaking the monolith, it’s never about cutting slate. It’s more like chopping trees where there are branches and nodes. You’ll try to follow the line, but you’ll realize that something isn’t getting separated that easily: there will be something that is shared in the wrong way, but that’s also big and dangerous to play with.28And this is where the metaphor sounds a little too easy for me. There are ways to deal with this problem (I talked about it in an old presentation: What lies beneath), but they require a given degree of mastery.',\n",
       "    'token_count': 614},\n",
       "   {'tile': 'What’s left out?',\n",
       "    'content': 'A few concepts are part of the game but seem to be missing from the conversation.• Organization size: Team Topologies starts being interesting when your development shop has 20 or 50 or more people, while you’ll have Bounded Contexts also when you’re coding in solo mode.• Business pressure & portfolio management: designing the perfect harmony between teams will fail miserably without some health check in terms of backlog pressure. If teams are under pressure, a healthy collaboration will not happen, but I still see too many organizations unable to plan for multiple dependent teams.',\n",
       "    'token_count': 111},\n",
       "   {'tile': 'A journey, not a destination',\n",
       "    'content': 'I kept my favorite thought for last: I think the most important outcome of the discussion around Team Topologies nowadays is about what a good desirable state looks like. Most organizations have never seen a healthy organization (harsh but true), so providing a reference model is definitely a good thing.Please don’t fall into the trap of considering such a desirable state as stable or solving the problem of team structure once and forever. Every solution will be ephemeral by design. Collaborations are temporary and will need to be reviewed whenever the context changes. But you’ll definitely have better tools to make the right decision.29',\n",
       "    'token_count': 120},\n",
       "   {'tile': 'Academy', 'content': '', 'token_count': 0},\n",
       "   {'tile': 'Increase awareness at scale with on-demand video learning on the Team Topologies Academy:',\n",
       "    'content': '',\n",
       "    'token_count': 0},\n",
       "   {'tile': '• Team Topologies Distilled• Platform as a Product• Team Topologies for Managers• Independent Value Streams with Domain-Driven Design• and more',\n",
       "    'content': '',\n",
       "    'token_count': 0},\n",
       "   {'tile': 'Live online', 'content': '', 'token_count': 0},\n",
       "   {'tile': 'Learn core Team Topologies principles and patterns with live online workshops delivered by official partners.',\n",
       "    'content': '',\n",
       "    'token_count': 0},\n",
       "   {'tile': 'teamtopologies.com/learn', 'content': '', 'token_count': 0}]},\n",
       " {'header': 'Exploring Team and Service Relationships with Team Topologies & Context Maps',\n",
       "  'sections': [{'tile': '',\n",
       "    'content': 'Michael Plöd, Fellow at INNOQOver the past two years, there has been a great deal of enthusiasm in the Domain-Driven Design community around the book Team Topologies by Matthew Skelton and Manuel Pais. In particular, the book has been praised in the highest of terms by community members who are intensively involved with the topic of sociotechnical architectures. Team Topologies is primarily about setting expectations for team behavior and interactions (and therefore setting expectations for software behavior and interactions). In doing so, the authors have created an appealing verbal and visual language. However, in the area of strategic Domain-Driven Design there are also Context Maps, which focus at least partially on similar topics. This article will highlight where Team Topologies and Context Maps are similar, where there are differences, and, most importantly, how to combine both ideas well.',\n",
       "    'token_count': 172},\n",
       "   {'tile': 'Introduction to Team Topologies and Context Maps',\n",
       "    'content': 'Team Topologies defines four different kinds of teams:• Stream-aligned Team: aligned to a single valuable stream of work.• Complicated Subsystem Team: builds and maintains a part of the system that depends heavily on specialist knowledge.• Platform Team: provides a platform on which Stream-aligned Teams can deliver work autonomously.• Enabling Team: Contains specialists who coach or mentor other (mostly stream-aligned) teams.31In addition, there are three different modes of interaction between those teams in Team Topologies:• Collaboration• X-as-a-Service• FacilitatingTeam Topologies uses a clear visual language:Stream-aligned Teams are shown as a yellow rounded rectangle (always horizontally to emphasize a left-to-right flow of change). Enabling Teams (in red) effectively ‘cut across’ the flow of change and are therefore shown vertically. Complicated Subsystem Teams deal with a discrete subsystem - shown as an orange octagon (or sometimes an orange diamond). Platform Teams are shown as a blue rectangle.The Collaboration interaction mode is shown as a purple parallelogram. The X-as-a-Service interaction mode is shown as a gray triangle. The Facilitating interaction mode is shown as a green circle.32More details about the Team Topologies visual language can be found at shapes.teamtopologies.comContext Maps were introduced 18 years ago in the original Domain-Driven Design book by Eric Evans. They define three types of team dependencies and 7 patterns. Vaughn Vernon added two additional patterns in his Implementing Domain-Driven Design book. Context Maps focus on the relationship between Bounded Contexts and the teams responsible for those Bounded Contexts. A Bounded Context can be defined as a boundary for a model expressed in a consistent ubiquitous language tailored around a specific purpose. Newer perspectives also mention the Bounded Context as a team-first boundary which minds the cognitive load of a team. The Team Topologies book itself dedicates a small chapter to this concept.The team dependencies according to Context Maps are:• Mutually Dependent: the actions of each team have an impact on the other team.• Upstream / Downstream: The actions of one team have an impact on the other team, but no vice-versa.• Free: there is no impact of actions on the other teams.The patterns of Context Maps are determined by various questions like:• Who provides services / interfaces (e.g. Open-host Service, Published Language)?• How do systems deal with Domain Models (e.g. Conformist, Anticorruption Layer, Shared Kernel)?• Who can raise requirements against others (e.g. Customer-Supplier)?• How about the relationship between teams (e.g. Partnership, Separate Ways)?• Which parts of a system are a mess (e.g. Big Ball Of Mud)?An overview and description of all of the Context Map patterns can be found at github.com/ddd-crew/context-mapping.33',\n",
       "    'token_count': 582},\n",
       "   {'tile': 'How do Team Topologies and Context Maps correlate?',\n",
       "    'content': 'There are a couple of similarities between the two approaches. Both address the relationships between teams and to a certain degree the systems that they build. However, there are enough differences that make it interesting to combine both concepts.Both ideas address the relationships between teams. Team Topologies focuses on this topic, whereas Context Maps contain various patterns that describe team-specific situations. In addition, there is a high degree of similarity between the Context Map’s ‘Open-host Service’ pattern and the X-as-a-Service team relationship from Team Topologies. Both concepts also contain ways to describe a close collaboration between two teams and their systems. Team Topologies uses the Collaboration interaction mode for this while Context Maps use mutual dependency and the Partnership pattern for this scenario.34The first and foremost difference is in the perspective of each approach. Context Maps first of all address the contact between Bounded Contexts whilst Team Topologies has a team-first perspective. In an ideal world, this would not be a big issue, since one would aim for a strong alignment between Bounded Contexts and teams. In this case, both Context Maps and Team Topologies will fit perfectly.However, in the real world, we very often see one team being responsible for multiple Bounded Contexts:35Since the Domain-Driven Design world does not talk about types of teams but Team Topologies does, we can combine both ideas. What kind of a team is it that is responsible for one or more Bounded Contexts? The suitable candidates are:• Stream-aligned Teams• Platform Teams• Complicated Subsystem TeamsNote: The Enabling Team type from Team Topologies is not shown in this scenario because Enabling Teams do not have responsibility for business capabilities.Another aspect with a great deal of potential for a combination of both approaches is the X-as-a-Service relationship of Team Topologies. In this scenario, ‘one team consumes something that another team provides’ (Quote from the Team Topologies book). The corresponding concepts in the Context Map are an Upstream/Downstream relationship between two teams with an Open-host Service on a Bounded Context providing/exposing functionality.From this starting point lies a big potential for further deep dives into the relationship. In this case, you can get started with adding the team boundaries and team types to the Context Map. As a next step, we can dig deeper into this36X-as-a-Service relationship by using some of the Context Mapping patterns. We can visualize how the Domain Model provided by the Open-host Service propagates into the other Bounded Context by using the Anticorruption Layer and/or the Conformist pattern. This option allows you to take a closer look at how tightly or loosely two Bounded Contexts and even teams are coupled. Even if a team just consumes a service being provided, there is still a chance of a tight coupling on the downstream side if they conform to the model provided.Another option that you can explore is whether or not the consuming side has or should have some influence on the providing side. I am aware that this is not the key intention of the X-as-a-Service relationship in Team Topologies, but there is something in between a very close collaboration between two teams and one team providing services in a ‘take it or leave it’ manner. This scenario can be described by the Customer-Supplier pattern: one team will typically have a certain, well-defined right to raise requirements against the other team.Here are two examples. The image below depicts a Complicated Subsystem Team in the upstream which is responsible for multiple Bounded Contexts and provides a service to a Stream-aligned Team in the downstream which uses an Anti Corruption Layer:37The next scenario depicts two teams in a X-as-a-Service relationship in which the downstream (consuming) side may be allowed to raise some requirements for the provider.One more aspect that the team relationships of Team Topologies address rather indirectly is organizational solutions or manual steps. By organizational solutions or manual steps, I mean the lack of integration between two Bounded Contexts. Integration is often cumbersome and expensive to implement. Therefore, some teams avoid the effort and go for manual processes with minimal support from software. This is especially interesting when we aim to build Minimum Viable Products (MVPs). In this case, it is often viable that some back-office process steps do not get triggered through a perfectly implemented integration between the Bounded Contexts of two teams but rather through manual processes. Let’s take a mortgage loan application as an example and think of two Bounded Contexts with corresponding teams: a loan application and a contract proposal. We don’t expect many contracts in the first few months, so manually sending contract proposals may be a good idea for a minimum viable product.38Which Team Topologies relationship would exist between those two teams? Still, X-as-a-Service, because there is still a (manual) service involved? I think it is better to make this relationship more explicit by adding the Separate Ways pattern to the observation. Yes, a service is being provided, but not with a perfectly implemented integration.',\n",
       "    'token_count': 1020},\n",
       "   {'tile': 'Summary',\n",
       "    'content': 'Team Topologies and Context Maps have a certain degree of overlap in their intention. However, both can be combined in a variety of ways to unlock deeper insights into the relationships between teams and Bounded Contexts. As a starting point, I suggest beginning with Team Topologies and adding the Context Map patterns as needed. But please, don’t overload your diagrams with everything you can squeeze into them, because they will become very hard to understand. Always keep the readers of your diagrams in mind: you are creating the diagrams for them, not for yourself. 😀3940',\n",
       "    'token_count': 113},\n",
       "   {'tile': 'Accelerator Programme', 'content': '', 'token_count': 0},\n",
       "   {'tile': 'Join our Accelerator Programme to speed adoption of Team Topologies with help from Team Topologies experts (TTVPs and authors)',\n",
       "    'content': '',\n",
       "    'token_count': 0},\n",
       "   {'tile': 'Guided Workshops', 'content': '', 'token_count': 0},\n",
       "   {'tile': 'Use our live online Guided Workshop sessions to accelerate adoption and increase practical awareness of Team Topologies:',\n",
       "    'content': '',\n",
       "    'token_count': 0},\n",
       "   {'tile': '• Blockers to Fast Flow• Define and Evolve a Platform• Team Topologies Applied• and more...',\n",
       "    'content': '',\n",
       "    'token_count': 0},\n",
       "   {'tile': 'teamtopologies.com/adopt', 'content': '', 'token_count': 0}]},\n",
       " {'header': 'Architect Your Business with Domain-Driven Design and Team Topologies',\n",
       "  'sections': [{'tile': '',\n",
       "    'content': 'Nick Tune, Principal Consultant at Empathy SoftwareWhat does it take to become a high-performing technology-savvy organization? Is it sufficient to just have a revolutionary strategy, a few rockstar engineers, or cutting-edge tech? In my experience, it’s extremely unlikely that being exceptional at any one thing and mediocre at everything else is going to result in high-performance. Excelling at many things, from strategy, to culture, to technology, is essential. I would go further and say that doing each of those things well is still not enough. It’s essential to see the big picture and connect and co-design the dots of strategy, culture, and technology.',\n",
       "    'token_count': 133},\n",
       "   {'tile': 'Why the combination of DDD and Team Topologies works so well',\n",
       "    'content': 'If connecting the dots is essential, then combining ideas from different communities and topics is also essential. That’s why the combination of Domain-Driven Design (DDD) and Team Topologies is proving to be a successful formula. Both approaches address different aspects of becoming a high-performing organization. They are two pieces of the puzzle that fit together neatly. When you think about the architecture of a business, all of the pieces fall into place.42A company offers one or more products to one or more markets to create a value exchange. Value is created for customers and business value is received in return. Digital products are powered by software, which has an architecture. And the architecture is developed by engineering teams within the organization.The relationship between the architecture of an organization and the architecture of the software is crucial, as Conway’s Law implies. If a team owns a loosely-coupled part of the architecture, they can make changes quickly and improve the rate of product development. But if they own a part of the architecture that is highly-coupled to other parts, every change will require coordination with other teams and the rate of product development will be orders of magnitude slower.So, how do we create loose coupling in software to enable more autonomous teams? The answer can be found by reflecting on what a software system is. A software system is a model of business concepts. In Uber’s software, they have business concepts like trips and waypoints. The key to loose coupling is to find business concepts that change together and situate them in the same architectural component (like a microservice or monolith module). When changes normally occur within a single component, owned by a single team, there will be fewer technical and organizational dependencies.Defining service boundaries, however, is a complex challenge that many organizations struggle with. Understanding business processes and concepts and modeling them as loosely-coupled architectural components is a little more work than just underlining nouns and verbs in a requirements document. This is where DDD aims to provide value, by being an approach to software development that treats domain discovery and modeling as a primary concern, with a particular emphasis on collaboration across disciplines.',\n",
       "    'token_count': 426},\n",
       "   {'tile': 'EventStorming for fun and profit',\n",
       "    'content': 'One of the most DDD-esque activities is EventStorming, a collaborative domain discovery and modeling approach invented by Alberto Brandolini. EventStorming brings together domain experts, technology experts, and anybody else loosely involved in the software development process. Gathered around a large amount of wall space (minimum 8 meters), participants begin adding domain events, like Order Placed and Balance Transferred, for parts of the system with which they43are familiar. Soon, everybody’s domain knowledge is combined into one bigtimeline representing end-to-end business processes.Once formed, an event storm can be sliced up into chunks.1 Each chunk contains a selection of business concepts that appear close together in the business process, indicating that they are likely to change together. If you remember, this was the key ingredient for creating a loosely-coupled system. So, the chunks on an EventStorm, referred to as domains or subdomains, become the candidate boundaries for the software architecture and teams. In any system, there will always be some coupling and co-change.Some further benefits of EventStorming are that it also improves cross-team collaboration and visibility so that when multiple teams must work together on a new feature, they’re better equipped to do this. Another benefit of EventStorming is that teams learn more about the domain and become more empowered to shape the products they are building. This is important because whole-team collaboration has been identified as a top source of product innovation.44',\n",
       "    'token_count': 290},\n",
       "   {'tile': 'Validating domain boundaries with Domain Message Flow Modeling',\n",
       "    'content': 'After identifying domain boundaries on an EventStorm, another DDD technique can help you validate and refine the boundaries and identify the responsibilities of each domain. Domain Message Flow Modeling is a technique for visualizing the communication between different domains in end-to-end flows such as placing an order. A Domain Message Flow uses commands, events, and queries to represent collaboration in the domain. This notation maps directly onto a software architecture, which helps to prove that the logical design will work in reality. This technique is also great for uncovering hidden coupling at an early stage.After identifying and refining domain boundaries, Team Topologies enters the picture and the focus shifts. The next step is to verify that the domain boundaries will map onto an organizational structure that enables a fast flow of changes. The first thing to consider is cognitive load: will each domain be manageable for a long-lived team of 5-9 people? If it seems too big or complex, it will need to be split up.45',\n",
       "    'token_count': 194},\n",
       "   {'tile': 'Assessing cognitive load with the Bounded Context Canvas',\n",
       "    'content': 'The Bounded Context Canvas is a tool created by the DDD community which maps out the purpose, responsibilities, collaborators, and complexity of each service. This canvas can help you to see if a domain is too big or complex for a single team.After validating and refining your domain boundaries, you can build a team topology around them. Each domain will be owned by a Stream-aligned, Complicated Subsystem, or Platform Team and the interactions between them will need to be carefully considered.The design process may sound a bit waterfall, but it should be a continuous and evolutionary process. Both the team boundaries and domain boundaries may evolve and even diverge over time as knowledge is gained and the business context changes. All of the techniques mentioned in this article should be part of your toolbox and used as regularly as needed, not just at the beginning of an initiative.46',\n",
       "    'token_count': 170},\n",
       "   {'tile': 'Core Domain Charts provide a strategic reference point',\n",
       "    'content': 'One other technique that often provides value is the Core Domain Chart, another DDD community initiative. This tool helps you to visualize the strategic importance of each domain and ensure that your domain and organizational boundaries are optimized for maximum exploitation in core domains. Core domains are those that form the core of the business strategy.By laying out each domain on a Core Domain Chart and overlaying the Team Topology, it becomes easier to identify mismatches which are likely to have strategic consequences. For example, when a Stream-aligned core domain team is collaborating with three Stream-aligned supporting domain teams, it’s a warning sign that a core domain team has an excessive cognitive load and is being slowed down by too much collaboration. Or, when multiple core domains are all trying to evolve in different directions but they all depend on a Stream-aligned supporting domain team that is becoming a bottleneck. These problems are of high strategic importance because innovation in core domains is being stifled, and the core domains are where competitive advantage is gained and maintained.47',\n",
       "    'token_count': 200},\n",
       "   {'tile': 'Next Steps with DDD and Team Topologies',\n",
       "    'content': 'A high-performing organization excels in many areas. When used together, Domain-Driven Design and Team Topologies provide key insights and techniques for architecting your business if you understand their strengths and apply them appropriately.If you’re interested in learning more about Domain-Driven Design, check out Welcome to DDD, and the DDD Starter Modeling Process. These are completely free community initiatives created to help newcomers learn and apply DDD with a hands-on focus. You may also want to check out my free Strategic DDD Kata which provides an example Eventstorm that you can slice up into domains as well as practice Domain Message Flow Modeling and Core Domain Charts.48',\n",
       "    'token_count': 131},\n",
       "   {'tile': 'Enhance your transformation program with ongoing expertise',\n",
       "    'content': '',\n",
       "    'token_count': 0},\n",
       "   {'tile': 'Our expert practitioners provide advice, insights, and guidance over 6-18 months as you define and scale your transformation program.',\n",
       "    'content': '',\n",
       "    'token_count': 0},\n",
       "   {'tile': 'Regular workshops and insights', 'content': '', 'token_count': 0},\n",
       "   {'tile': 'Increase confidence in the success of your transformation program via regular sessions from TT experts:',\n",
       "    'content': '',\n",
       "    'token_count': 0},\n",
       "   {'tile': '• Workshops• Q&A and talks• Expert Insight sessions• and more…',\n",
       "    'content': '',\n",
       "    'token_count': 0},\n",
       "   {'tile': 'teamtopologies.com/transform', 'content': '', 'token_count': 0}]},\n",
       " {'header': 'Finding Good Stream Boundaries with Independent Service Heuristics and User Needs Mapping',\n",
       "  'sections': [{'tile': '',\n",
       "    'content': 'Rich Allen and Matthew SkeltonWhen designing organizations for a fast flow of change, we need to find effective boundaries between different streams of change to ensure that we create good team boundaries. This can be achieved by identifying potential boundaries across services, domains, applications, or streams. This article considers different ways that you could approach boundary exploration.',\n",
       "    'token_count': 67},\n",
       "   {'tile': 'Identifying boundaries with Domain–Driven Design',\n",
       "    'content': 'When we first think of the terms ‘domain’ or ‘boundary’ in a software context, it is likely that our first thoughts are of Domain-Driven Design (DDD). The book by Eric Evans, Domain-Driven Design: Tackling Complexity in the Heart of Software, published in 2003, has stood the test of time and provides significant insights into how to structure software that can be aligned with existing business domains. The high-level definition of the practice is ‘an approach to developing software for complex needs by deeply connecting the implementation to an evolving model of core business concepts’. With the introduction of terms like ‘Bounded Contexts’ and ‘ubiquitous language,’ it provides a vast library of practices and techniques to help practitioners tame the complexities of modern software development. Since the original publication, there have been numerous others that have attempted to simplify and make50the concepts more digestible, for example, Domain-Driven Design Distilled by Vaughn Vernon and The Anatomy of Domain-Driven Design by Scott Millet and Sam Knight.There have also been many contributions from the wider DDD community, including new techniques such as EventStorming. The DDD Crew have a great set of resources available which includes a DDD Starter Modeling Process, Core Domain Chart examples, Context Map Cheat Sheets, an EventStorming Glossary Cheat Sheet, a Bounded Context Canvas, and many more. The value and benefits provided by a DDD approach are clear and taking the time to learn each of the techniques will be a sound long-term investment. However, many people struggle to get started adopting the practices as they can often be seen as overwhelming.',\n",
       "    'token_count': 329},\n",
       "   {'tile': 'Taking a different approach: Independent Service Heuristics',\n",
       "    'content': 'Independent Service Heuristics (ISH) is a technique invented by the authors of Team Topologies, Matthew Skelton and Manuel Pais. It has been subsequently refined by others, including Team Topologies Valued Practitioners (TTVPs) and members of the wider DDD community. You can find more information via the Independent Service Heuristics GitHub repository which is openly provided via the CC BY-SA license.ISH is an intermediate approach that can help to introduce the principles of DDD without some of the abstract terminology that can often be a barrier to the adoption of DDD. ISH provides simple rules-of-thumb or clues that can be used to identify candidate value streams and domain boundaries by seeing if they could be run as a separate SaaS/cloud product. It is intended to stimulate conversation and provide a frame of thinking about basic domain concepts. It does not attempt to be a perfect ‘catch-all’ tool. After using ISH to identify potential domain boundaries or value streams, it often makes sense to then delve deeper into the problem space using other DDD techniques.51',\n",
       "    'token_count': 217},\n",
       "   {'tile': 'Exploring boundaries using Independent Service Heuristics',\n",
       "    'content': \"Independent Service Heuristics (ISH) starts with a simple question, ‘Could this thing be run as a cloud-hosted (SaaS) service or product?’ On the surface, this almost seems too simple. How can that one question provide answers that help us to uncover potential domain boundaries and value streams? The terms Cloud and Software as a Service (SaaS) have been in the public domain for long enough that most people will understand what we mean when we ask the question. And the answer to the question is often either yes, no, or maybe. We can then follow up with a series of clarifying questions to determine whether the area under focus could truly be a potential domain boundary.In any process or methodology, getting started and taking the first step is normally the hardest part. In the case of ISH, that first step is deciding where to focus your attention. Essentially, we just need to choose an area of the business that needs to be represented in software. This could be a user journey, a ‘product’, a possible business domain, a software service, an entire software application, a set of tasks for a single user persona, a possible value stream, etc.The important thing here is that we actively choose an area and get started. The process is quick enough that we won’t waste too much time if we happen to choose an area that does not naturally fit a domain boundary but at least we can discount it and move on to the next candidate.Imagine a fictional company called Footprints Tours which offers ‘alternative’ walking tours of cities exploring their social and cultural history. They provide both guided and self-guided tours and have implemented a monolith website and mobile application to serve all of their customer needs. The flow of development has slowed down significantly as the code base has grown over time. Using Independent Service Heuristics, they are looking to understand how they might re-organize the teams and therefore the applications/services to improve flow and alignment with the needs of their customer. The first step is to capture some possible fracture planes, such as those shown in the image below.52Once a candidate domain, service, application, or value stream has been identified, the next step is to go through a series of questions to identify whether or not we have found a good candidate for being a separate stream of change. The high-level checklist of questions is as follows (as of January 2023):1. Sense-check: Could it make any logical sense to offer this thing ’as a service’?• Is this thing sufficiently independent?• Would consumers understand or value it?• Would it simplify execution?2. Brand: Could you imagine this thing branded as a public cloud service (like AvocadoOnline.com 🥑 )?• Would it be a viable business (or ‘micro-business’) or service?• Would it be a compelling offering?• Could a marketing campaign be convincing?533. Revenue/Customers: Could this thing be managed as a viable cloud service in terms of revenue and customers?• Would it be a viable business (or ‘micro-business’) or service?• What would a subscription payment include?• Is there a clearly defined customer base or segment?4. Cost tracking: Could the organization currently track costs and investment in this thing separately from similar things?• Are the full costs of running this thing transparent or possible to discover? Consider infrastructure, data storage, data transfer, license costs, etc.• Is the thing too interconnected with other things in the organization? Or fairly separate?• Does the organization track this separately?5. Data: Is it possible to clearly define the input data (from other sources) that this thing needs?• Is it dependent on lots of data from multiple sources? Or fairly independent?• Are the sources internal (under our control) or external?• Is the input data clean or messy?• Is the input data provided in a self-service way? Can the team consume the input data ’as a service’?6. User Personas: Could this thing have a small/well-defined set of user types or customers (user personas)?• Is the thing meeting specific user needs?• Do we know (or can we easily articulate) these user types and their needs?7. Teams: Could a team or set of teams effectively build and operate a service based on this thing?• Would the cognitive load (breadth of topics/context switching) be bounded to help the team focus and succeed?• Would significant infrastructure or other platform abstractions be needed?548. Dependencies: Would this team be able to act independently of other teams for the majority of the time, to achieve their objectives?• Is this thing logically independent from other things?• Could the team ‘self-serve’ dependencies in a non-blocking manner from a platform?9. Impact/Value: Would the scope of this thing provide a team with an impactful and engaging challenge?• Is the scope big enough to provide an impact? Would the scope be engaging for talented people?• Is there sufficient value to customers and the organization that the value would be clearly recognized?10. Product Decisions: Would the team working on this thing be able to ‘own’ their product roadmap and the product direction?• Does this thing provide discrete value in a well-defined sphere of execution? • Can the team define their own roadmap based on what they discover is best for the product and its users or is the team always driven by the requirements and priorities of other teams?Answer these questions for each of the candidate streams you have identified. The more 'yes' or 'maybe' answers a possible stream has, the greater the chance that you have found a good candidate for being a separate stream of change.155Answering these initial questions about the service should help to uncover potential candidates for separate streams of change, but it may be useful to consider other aspects too, such as whether the language used to describe services is the same or different and where services are currently tightly-coupled.\",\n",
       "    'token_count': 1209},\n",
       "   {'tile': 'Case Study - using the Independent Service Heuristics at Zalora',\n",
       "    'content': 'ZALORA is the leading fashion & lifestyle destination for Southeast Asia, carrying an ever-expanding line-up of local and international brands. In 2021, as it scaled by more than 60%, it was on a drive to enhance customer experience and reduce time-to-market. As part of this, Zalora began exploring the use of Team Topologies ideas and practices.During a multi-day workshop with a wide range of attendees (led by Team Topologies co-author Matthew Skelton), Zalora stakeholders were introduced to the Independent Service Heuristics. They learned how to use the ISH approach to find candidate flow-aligned boundaries and interpret the results, allowing the insights to guide and inform conversations with different parts of the business.56After the workshop, Zalora ran further internal sessions, expanding the use of ISH to find further possible flow-aligned boundaries. The straightforward language of ISH helped to facilitate conversations between many different parts of Zalora, including: technology, product, warehouse, logistics, and business strategy. The Independent Service Heuristics acted as a frame or ‘lens’ through which to talk about priorities, flow, and ownership. The very visual style of the ISH exploration grid provided a way to frame conversations:57Zalora used the ISH questions so extensively that they contributed three new heuristics to the ISH collection: Dependencies, Impact/Value, and Product Decisions.“We first used the Independent Service Heuristics as part of Team Topologies during our workshop with Matthew Skelton in August 2021. The framework and shared language of the ISH approach were transformational to the discussions we later had about our organization and team structure. Not only did this approach help us discover and align on new stream-aligned Tteams, but it also helped us redefine other teams as Platform, Complicated Subsystem, and Enabling Teams. Thanks to the Team Topologies and ISH framework, our team structure is more autonomous, meaningful, and productive. We were able to take this simple but powerful framework in its visual, grid-based format and have further discussions which led to us expanding the scope to reflect additional angles that we knew would be essential for sustainable team boundaries. It was great to be able to contribute our updates to the ISH code repo so others can make use of our insights!” — Liam Hutchinson, Group Director of Product, Zalora',\n",
       "    'token_count': 485},\n",
       "   {'tile': 'Exploring boundaries from a user perspective with User Needs Mapping',\n",
       "    'content': \"The ISH approach looks at existing services, applications, or value streams to determine whether they might form good boundaries for teams. However, a slightly different perspective can be provided by User Needs Mapping.The term User Needs Mapping was coined by Rich Allen, a TTVP, during the preparation of some workshops focused on Team Topologies. It is based on one of the early stages of the Wardley Mapping process. Wardley Mapping builds upon ancient principles taken from Sun Tzu’s The Art of War. It provides a great58way for business leaders to map out a strategy by taking into account several factors including purpose, landscape, climate, doctrine, and leadership in a continuous cycle of observing, orienting, deciding, and acting (the OODA loop from John Boyd).One of the core principles (and potentially the most intimidating part) of Wardley Mapping is the use of an evolutionary axis that runs from Genesis on the left through Custom Built, Product, and finally Commodity on the right of the map. Items are plotted on the map with respect to how ‘evolved’ the item is. Something new to the world would be added to the Genesis column, whereas something widely available and undifferentiated would be plotted in the Commodity column. This allows the mapper and colleagues taking part in the mapping session to begin strategic conversations about the current state of items on the map and also discuss how they may evolve in the future (based on market trends etc). This means they can make more informed, strategic decisions about how to plan for the future.The power of Wardley Mapping lies within this unique ability to capture ‘movement’ or evolution over time. Changing the position of an item changes its meaning on the map and puts the focus of the conversation onto the map. However, in much the same way as DDD, people can find the practice intimidating in the first instance, since there is so much to take in. In the same way that ISH provides a lightweight alternative to introduce DDD concepts, User59Needs Mapping provides a lightweight entry into the world of Wardley Maps. The Wardley Mapping process consists of 5 steps:1. Define Your ‘True North’ (i.e. our customer/user).2. User’s Needs – Needs to be met.3. Capabilities – How you’re going to meet your user’s needs. 4. Value Chain – A list of users, needs, and capabilities becomes a value chain when you add dependency relationships.5. Wardley Map – A value chain becomes a Wardley Map when you determine how evolved everything is and position it accordingly (left-to-right) on the evolutionary axis.The term User Needs Mapping attempts to capture the first 4 steps of the Wardley Mapping process as we believe it can provide initial value for identifying potential team boundary issues without progressing into step 5 and the evolutionary world of Wardley Maps.User Needs Mapping begins by simply asking the question ‘Who are your users/customers?’. It is still surprising how many people are unable to concisely answer that seemingly simple question. Many people might know who their users are but haven’t documented it or shared it with anyone. User Needs Mapping provides a simple canvas to begin the process and starts by capturing the user and their needs.60After capturing some user needs, the next phase is mapping the dependency chain. This phase essentially uses the vertical ‘value chain’ axis of a Wardley Map without the evolutionary horizontal axis. The map is ‘anchored’ by the user at the top of the canvas and the user's needs are linked to each user. Focusing on one need at a time, we plot what services, dependencies, or business capabilities are used to meet that particular need. The vertical axis represents how visible the capability is to the user.The same fictional company Footprints Tours introduced in the previous section is now looking to use User Needs Mapping to understand how it might re-organize the teams to improve flow and alignment with the needs of their customer.We could begin the exploration with a user journey such as ‘Finding a self-guided tour’. In this scenario, we can imagine what would be required when a user needed to find a good self-guided tour. The first service they might use is a search engine such as Google or Bing (an external service). For our ‘Find a tour’ service to appear in the search engine results, we would need some Search Engine Optimization (SEO) and this would lead the user to that page on our website. Once the user has landed on the ‘Find a tour’ page, they might be61encouraged to use the Tour Search service (an internal service dependency) to find a tour that looks good for them. The Tour Search service might require a database that contains data about the tours. The database is provided as a Platform as a Service offering from a cloud provider which then becomes a further external dependency that can be mapped on the canvas. As each dependency becomes less visible to the end user, it is plotted further down the vertical axis.After performing an initial mapping process, we can explore overlaying the Team Topologies team types to highlight where we think some possible team boundaries might exist.After this initial session and seeking feedback, we might decide to ‘drill in’ to some areas such as the website to identify which parts of that system might be owned by specific teams and therefore be a good candidate for stream-alignment.62As we can see, the database is potentially a shared dependency between the two stream-aligned teams. This raises questions such as whether data should be stored in a single database. Should the data be owned by a database platform team? Is there data that is only relevant to the individual streams? Could this database be split into two databases provided by a platform but owned by the streams?After we have drilled down the dependency chain as far as we want to go, we then look at the next user need and repeat the process. As we do this, we begin to uncover and visualize the dependencies between the services and capabilities within our organization. The more we do this, the more we might spot patterns or opportunities to decouple services to provide faster flows of change or introduce other types of teams to help reduce the cognitive load of stream-aligned teams.63In summary, the User Needs Mapping process is as follows:1. Create a list of customer/user types.2. Identify user needs (for each type of user).3. Identify what capabilities/components/services are required to meet each user need.4. Overlay potential team boundaries using the Team Topologies shapes.5. Annotate the map with questions about suspect dependencies.6. Discuss how the dependencies might be broken and capture your thoughts on other ways to organize the dependencies.7. Repeat steps 1 to 5 as necessary until you identify potential team boundaries that ‘feel’ right.After you have completed the User Needs Mapping process, the next logical step may be to introduce the horizontal evolutionary axis of Wardley Mapping. It can often be an interesting thought experiment to consider whether products or services you are currently ‘custom building’ with specific teams should actually be purchased as a ‘product’ or even used as a ‘commodity’. Or maybe the products and services you are building now will evolve within the next couple of years? This might prompt the question of whether to start preparing for the inevitable evolution now.\",\n",
       "    'token_count': 1477},\n",
       "   {'tile': 'Summary',\n",
       "    'content': 'In this article, we looked at how we could use two approaches, Independent Service Heuristics and User Needs Mapping, as a lightweight introduction/alternative to DDD concepts and to explore application and service boundaries that could lead to good stream and team boundaries. With the goal of achieving a fast flow of change, taking a team-first approach and understanding how those teams interact is of utmost importance. Why not give Independent Service Heuristics and User Needs Mapping a try the next time you need to identify boundaries within your organization?64',\n",
       "    'token_count': 105}]}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4-turbo\")\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    if not text:\n",
    "        return 0\n",
    "    return len(enc.encode(text))\n",
    "\n",
    "for header in point:    \n",
    "    for section in header[\"sections\"]:\n",
    "        section[\"token_count\"] = count_tokens(section.get(\"content\", \"\"))\n",
    "\n",
    "point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ff6decd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./.venv/lib/python3.13/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in ./.venv/lib/python3.13/site-packages (from langchain) (0.3.79)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./.venv/lib/python3.13/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in ./.venv/lib/python3.13/site-packages (from langchain) (0.4.34)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.13/site-packages (from langchain) (2.12.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.13/site-packages (from langchain) (2.0.44)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.13/site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.13/site-packages (from langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./.venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain_experimental in ./.venv/lib/python3.13/site-packages (0.3.4)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in ./.venv/lib/python3.13/site-packages (from langchain_experimental) (0.3.31)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.28 in ./.venv/lib/python3.13/site-packages (from langchain_experimental) (0.3.79)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in ./.venv/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in ./.venv/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.0.44)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in ./.venv/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in ./.venv/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.13.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in ./.venv/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in ./.venv/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.11.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in ./.venv/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.34)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./.venv/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in ./.venv/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.3.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./.venv/lib/python3.13/site-packages (from langchain<2.0.0,>=0.3.27->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.13/site-packages (from langchain<2.0.0,>=0.3.27->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.25.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (4.11.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./.venv/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.32.5->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.32.5->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.5.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain_openai in ./.venv/lib/python3.13/site-packages (0.3.35)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.78 in ./.venv/lib/python3.13/site-packages (from langchain_openai) (0.3.79)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.104.2 in ./.venv/lib/python3.13/site-packages (from langchain_openai) (1.109.1)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in ./.venv/lib/python3.13/site-packages (from langchain_openai) (0.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./.venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.4.34)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (2.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.78->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.25.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (4.11.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.13/site-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.13/site-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (0.11.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.13/site-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.13/site-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain_openai) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.13/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2025.9.18)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (2.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain\n",
    "%pip install langchain_experimental\n",
    "%pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de7f651d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 42 text sections.\n"
     ]
    },
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     14\u001b[39m             texts.append(section[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExtracted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(texts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m text sections.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m text_splitter = SemanticChunker(\u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     19\u001b[39m documents = text_splitter.create_documents(texts=texts, metadatas=[{} \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m texts])\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCreated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m documents.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/rag-fast-flow/.venv/lib/python3.13/site-packages/langchain_openai/embeddings/base.py:331\u001b[39m, in \u001b[36mOpenAIEmbeddings.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m         \u001b[38;5;28mself\u001b[39m.http_client = httpx.Client(proxy=\u001b[38;5;28mself\u001b[39m.openai_proxy)\n\u001b[32m    330\u001b[39m     sync_specific = {\u001b[33m\"\u001b[39m\u001b[33mhttp_client\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.http_client}\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     \u001b[38;5;28mself\u001b[39m.client = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m.embeddings  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.async_client:\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.openai_proxy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.http_async_client:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/rag-fast-flow/.venv/lib/python3.13/site-packages/openai/_client.py:135\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    133\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    136\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    137\u001b[39m     )\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[32m    139\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "import json\n",
    "\n",
    "with open(JSON_OUTPUT_PATH, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract all content from the sections\n",
    "texts = []\n",
    "for header in data:\n",
    "    for section in header[\"sections\"]:\n",
    "        if section.get(\"content\"):\n",
    "            texts.append(section[\"content\"])\n",
    "\n",
    "print(f\"Extracted {len(texts)} text sections.\")\n",
    "\n",
    "text_splitter = SemanticChunker(OpenAIEmbeddings())\n",
    "documents = text_splitter.create_documents(texts=texts, metadatas=[{} for _ in texts])\n",
    "print(f\"Created {len(documents)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73dd801",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad9835b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created embeddings for 54 sections\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "# Initialize OllamaEmbeddings\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "# Load the JSON data\n",
    "with open(JSON_OUTPUT_PATH, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Process sections and create embeddings\n",
    "sections_with_embeddings = []\n",
    "\n",
    "for header in data:\n",
    "    for section in header[\"sections\"]:\n",
    "        if section.get(\"tile\"):  # Only process sections with titles\n",
    "            # Create embedding for the content\n",
    "            embedding_vector = embeddings.embed_query(section[\"content\"])\n",
    "            \n",
    "            # Create a section object with title, text, and embedding\n",
    "            section_obj = {\n",
    "                \"title\": section[\"tile\"],\n",
    "                \"text\": section[\"content\"],\n",
    "                \"embedding\": embedding_vector\n",
    "            }\n",
    "            \n",
    "            sections_with_embeddings.append(section_obj)\n",
    "\n",
    "print(f\"Created embeddings for {len(sections_with_embeddings)} sections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5345b92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sections_with_embeddings[0][\"embedding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffd3cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to /Users/gmanvel/repos/rag-fast-flow/data/sections_with_embeddings.json\n"
     ]
    }
   ],
   "source": [
    "# Save to JSON file\n",
    "output_file = \"/Users/gmanvel/repos/rag-fast-flow/data/sections_with_embeddings.json\"\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(sections_with_embeddings, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved embeddings to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jrs8woicmd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install qdrant-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6rj14nn4bzi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Qdrant at localhost:6333\n",
      "Collections: collections=[]\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "# Connect to local Qdrant instance\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "# Verify connection\n",
    "print(f\"Connected to Qdrant at localhost:6333\")\n",
    "print(f\"Collections: {client.get_collections()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o4xuusnev9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing collection 'fast_flow_sections'\n",
      "Created collection 'fast_flow_sections' with vector size 768 and cosine distance\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "collection_name = \"fast_flow_sections\"\n",
    "\n",
    "# Recreate collection (delete if exists)\n",
    "try:\n",
    "    client.delete_collection(collection_name=collection_name)\n",
    "    print(f\"Deleted existing collection '{collection_name}'\")\n",
    "except Exception as e:\n",
    "    print(f\"No existing collection to delete: {e}\")\n",
    "\n",
    "# Create new collection\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=768, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "print(f\"Created collection '{collection_name}' with vector size 768 and cosine distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcir98nninn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully inserted 54 points into 'fast_flow_sections' collection\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.models import PointStruct\n",
    "import json\n",
    "\n",
    "# Load embeddings from JSON\n",
    "embeddings_file = \"/Users/gmanvel/repos/rag-fast-flow/data/sections_with_embeddings.json\"\n",
    "with open(embeddings_file, 'r', encoding='utf-8') as f:\n",
    "    sections_data = json.load(f)\n",
    "\n",
    "# Prepare points for insertion\n",
    "points = []\n",
    "for idx, section in enumerate(sections_data):\n",
    "    point = PointStruct(\n",
    "        id=idx,\n",
    "        vector=section[\"embedding\"],\n",
    "        payload={\n",
    "            \"title\": section[\"title\"],\n",
    "            \"text\": section[\"text\"]\n",
    "        }\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "# Insert points into Qdrant\n",
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")\n",
    "\n",
    "print(f\"Successfully inserted {len(points)} points into '{collection_name}' collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "htyn299fkvp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify insertion by getting collection info\n",
    "collection_info = client.get_collection(collection_name=collection_name)\n",
    "print(f\"Collection '{collection_name}' info:\")\n",
    "print(f\"  - Total points: {collection_info.points_count}\")\n",
    "print(f\"  - Vector size: {collection_info.config.params.vectors.size}\")\n",
    "print(f\"  - Distance metric: {collection_info.config.params.vectors.distance}\")\n",
    "\n",
    "# Test a simple search with the first embedding\n",
    "if len(sections_data) > 0:\n",
    "    print(\"\\nTesting search with first section's embedding...\")\n",
    "    search_results = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=sections_data[0][\"embedding\"],\n",
    "        limit=3\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTop 3 similar sections:\")\n",
    "    for i, point in enumerate(search_results, 1):\n",
    "        print(f\"\\n{i}. Score: {point.score:.4f}\")\n",
    "        print(f\"   Title: {point.payload['title']}\")\n",
    "        print(f\"   Text preview: {point.payload['text'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d555ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = embeddings.embed_query(\"What is the Wardley doctrine?\")\n",
    "waldey_doctrine = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=query_vector,\n",
    "    limit=3,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "print(f\"\\nTop 3 similar sections:\")\n",
    "for i, point in enumerate(waldey_doctrine.points, 1):\n",
    "    print(f\"\\n{i}. Score: {point.score:.4f}\")\n",
    "    print(f\"   Title: {point.payload['title']}\")\n",
    "    print(f\"   Text preview: {point.payload['text']}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeeb656",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama_index\n",
    "%pip install llama_index-embeddings-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9998cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97937bae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sections_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     12\u001b[39m splitter = SemanticSplitterNodeParser(\n\u001b[32m     13\u001b[39m     buffer_size=\u001b[32m1\u001b[39m,\n\u001b[32m     14\u001b[39m     breakpoint_percentile_threshold=\u001b[32m70\u001b[39m,\n\u001b[32m     15\u001b[39m     embed_model=ollama_embeddings\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m points: \u001b[38;5;28mlist\u001b[39m[PointStruct] = []\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, section \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43msections_data\u001b[49m):\n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m#print(f\"Processing section title: {section['title']}\")\u001b[39;00m\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m#print(f\"Content:{section['text']}\")\u001b[39;00m\n\u001b[32m     22\u001b[39m     nodes = splitter.get_nodes_from_documents(documents=[Document(text=section[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m])])\n\u001b[32m     23\u001b[39m     chunks = [(node.embedding, node.get_content()) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes]\n",
      "\u001b[31mNameError\u001b[39m: name 'sections_data' is not defined"
     ]
    }
   ],
   "source": [
    "from qdrant_client.models import Distance, VectorParams\n",
    "from qdrant_client.models import PointStruct\n",
    "\n",
    "collection_name = \"fast_flow\"\n",
    "\n",
    "# Create new collection\n",
    "# client.create_collection(\n",
    "#     collection_name=collection_name,\n",
    "#     vectors_config=VectorParams(size=768, distance=Distance.COSINE),\n",
    "# )\n",
    "ollama_embeddings = OllamaEmbedding(model_name=\"nomic-embed-text\")\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=1,\n",
    "    breakpoint_percentile_threshold=70,\n",
    "    embed_model=ollama_embeddings\n",
    ")\n",
    "\n",
    "points: list[PointStruct] = []\n",
    "for index, section in enumerate(sections_data):\n",
    "    #print(f\"Processing section title: {section['title']}\")\n",
    "    #print(f\"Content:{section['text']}\")\n",
    "    nodes = splitter.get_nodes_from_documents(documents=[Document(text=section[\"text\"])])\n",
    "    chunks = [(node.embedding, node.get_content()) for node in nodes]\n",
    "\n",
    "    #print(f\"Number of chunks created: {len(chunks)}\")\n",
    "    for inner_index, (_, content) in enumerate(chunks):\n",
    "        if not content.strip() or content.strip() == \"Summary\":\n",
    "            continue\n",
    "        emb = ollama_embeddings.get_text_embedding(content)\n",
    "        point = PointStruct(\n",
    "            id=index*10 + inner_index,\n",
    "            vector=emb,\n",
    "            payload={\n",
    "                \"title\": section[\"title\"],\n",
    "                \"text\": content\n",
    "            }\n",
    "        )\n",
    "        points.append(point)\n",
    "        #print(f\"Embedding (first 5 values): {emb[:5]}\")\n",
    "        #print(f\"Content: {content}\\n\")\n",
    "\n",
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9633b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import QueryResponse\n",
    "\n",
    "query_vector = ollama_embeddings.get_text_embedding(\"What is the Wardley doctrine?\")\n",
    "waldey_doctrine: QueryResponse = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=query_vector,\n",
    "    limit=3\n",
    ")\n",
    "print(f\"\\nTop 3 similar sections:\")\n",
    "for i, point in enumerate(sorted(waldey_doctrine.points, key=lambda p: p.score, reverse=True), 1):\n",
    "    print(f\"\\n{i}. Score: {point.score:.4f}\")\n",
    "    print(f\"   Title: {point.payload['title']}\")\n",
    "    print(f\"   Text preview: {point.payload['text']}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739efae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#waldey_doctrine.points[1].payload['text']\n",
    "%pip install -U llama-index-core==0.11.15 llama-index-llms-ollama==0.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83f6b550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-index-core 0.14.5\n",
      "llama-index-llms-ollama 0.8.0\n",
      "llama-index-embeddings-ollama 0.8.3\n",
      "llama-index 0.14.5\n"
     ]
    }
   ],
   "source": [
    "import importlib.metadata\n",
    "\n",
    "for pkg in [\n",
    "    \"llama-index-core\",\n",
    "    \"llama-index-llms-ollama\",\n",
    "    \"llama-index-embeddings-ollama\",\n",
    "    \"llama-index\",\n",
    "]:\n",
    "    try:\n",
    "        print(pkg, importlib.metadata.version(pkg))\n",
    "    except importlib.metadata.PackageNotFoundError:\n",
    "        print(pkg, \"NOT INSTALLED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbc16b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from LLM:  The Wardley Doctrine is a framework developed by Simon Wardley for understanding, mapping, and navigating the evolution of different types of services or products within an organization's value chain. It provides a strategic lens to help organizations make informed decisions about where to focus their efforts for innovation, optimization, and investment.\n",
      "\n",
      "The Wardley Doctrine is based on four key principles:\n",
      "\n",
      "1. Mapping: Visualizing the components of a system and their evolutionary stage (genesis, custom built, productized, or infrastructure) using Wardley Maps. This helps organizations understand the competitive landscape, identify opportunities for innovation, and make informed decisions about where to invest.\n",
      "2. Positioning: Understanding the position of each component within the value chain and making strategic decisions about whether to build, buy, or avoid it. This helps organizations optimize their resources and focus on areas that provide the most value.\n",
      "3. Evolution: Recognizing that the evolutionary stage of a component can change over time, and understanding how to manage this change effectively. This helps organizations stay competitive in a rapidly changing market.\n",
      "4. Progression: Understanding the progression of components from genesis to infrastructure, and using this knowledge to guide strategic decisions about innovation, optimization, and investment. This helps organizations move towards more efficient and effective ways of delivering value to their customers.\n",
      "\n",
      "By applying the Wardley Doctrine, organizations can improve their ability to navigate complex systems, make informed decisions, and drive innovation and growth. It is often used in conjunction with other methodologies such as Domain-Driven Design (DDD) and Team Topologies to help organizations optimize their software delivery processes and improve their overall agility.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "\n",
    "\n",
    "llm = Ollama(model=\"mistral\", temperature=0)\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=MessageRole.SYSTEM,\n",
    "        content=\"You are a consultant specializing in fast flow methodologies using the Wardley mappings, DDD & Team Topologies. You are hired to consult and explain concepts around fast flow concepts.\"\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=MessageRole.USER,\n",
    "        content=\"What is the Wardley doctrine?\"\n",
    "    )\n",
    "]\n",
    "\n",
    "response = llm.chat(messages)\n",
    "print(f\"Response from LLM: {response.message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10316854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from LLM:  In Wardley Maps, the Doctrine refers to the set of assumptions or beliefs that underpin a particular domain or landscape. These doctrines are often deeply ingrained and can be difficult to change, as they influence how people think about problems and solutions within the domain.\n",
      "\n",
      "The Doctrine is represented on the Wardley Map as a horizontal line at the top, above the Landscape, Value Chain, and Episodes layers. It's important to understand the doctrines in a given landscape because they can significantly impact the strategies for evolution and transformation. By identifying and challenging limiting doctrines, it may be possible to find new ways to improve the landscape and achieve faster flow.\n",
      "\n",
      "For example, in a traditional IT landscape, a common doctrine might be that all applications must be built and maintained internally. Challenging this doctrine could lead to exploring options for outsourcing or using cloud-based solutions, which could help streamline processes and reduce costs.\n",
      "\n",
      "In the context of fast flow methodologies, understanding the doctrines in a landscape can help identify areas where change is needed to improve speed and agility. By challenging limiting doctrines and adopting new approaches, it may be possible to create faster flow and deliver value more quickly to customers.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import QueryResponse\n",
    "\n",
    "collection_name = \"fast_flow\"\n",
    "\n",
    "# Connect to local Qdrant instance\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "ollama_embeddings = OllamaEmbedding(model_name=\"nomic-embed-text\")\n",
    "\n",
    "user_query = \"What is the Doctrine in Wardley Maps?\"\n",
    "query_vector = ollama_embeddings.get_text_embedding(user_query)\n",
    "wardley_doctrine: QueryResponse = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=query_vector,\n",
    "    limit=1\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=MessageRole.SYSTEM,\n",
    "        content= (\n",
    "            f\"You are a consultant specializing in fast flow methodologies using the Wardley mappings, DDD & Team Topologies.\\n\"\n",
    "            f\"You are hired to consult and explain concepts around fast flow concepts.\"\n",
    "            f\"Context from your notes:{wardley_doctrine.points[0].payload['text']}\"\n",
    "        )\n",
    "\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=MessageRole.USER,\n",
    "        content=user_query\n",
    "    )\n",
    "]\n",
    "\n",
    "response = llm.chat(messages)\n",
    "print(f\"Response from LLM: {response.message.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
